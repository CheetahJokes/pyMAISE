{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c457a46-7467-4b8b-a751-970dfd4f9d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f05a358-941c-4665-bdd2-63d5c22d0ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "hi\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xarray as xr\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "#import pymaise \n",
    "print(\"hi\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyMAISE.datasets import load_anomaly\n",
    "from pyMAISE.preprocessing import train_test_split, scale_data, one_hot_encode, SplitSequence\n",
    "import pyMAISE as mai\n",
    "\n",
    "global_settings = mai.init(\n",
    "    problem_type=mai.ProblemType.CLASSIFICATION,   # Define a regression problem\n",
    "    cuda_visible_devices=\"-1\" ,                 # Use CPU only/ Delete line when run on GPU\n",
    "    verbosity = 3\n",
    ")\n",
    "#GRU 1st, GRU 2nd, and CNN LSTM for 2nd \n",
    "\n",
    "#add hyperp. tuning \n",
    "\n",
    "# call handler\n",
    "input_path = \"/home/jacc/pyMAISE/pyMAISE/datasets/DTL.npy\"\n",
    "output_path = \"/home/jacc/pyMAISE/pyMAISE/datasets/DTL_labels.npy\"\n",
    "#print(mai.__file__)\n",
    "#False, False, False:       X.shape = (1077, 4500, 14), Y.shape = (1077, 1)  one hot !\n",
    "#False, True, False:        X.shape = (1077, 4500, 14), Y.shape = (1077, 1)\n",
    "#False, False, True:        X.shape = (1077, 4500, 14), Y.shape = (1077, 4500, 1)\n",
    "#False, True, True:         X.shape = (1077, 4500, 14), Y.shape = (1077, 4500, 1)\n",
    "#True, False, True:         X.shape = (4846500, 14), Y.shape = (4846500, 1) !!!!\n",
    "#True, True, True:          X.shape = (4846500, 14), Y.shape = (4846500, 1)\n",
    "cond1 = False #stack series\n",
    "cond2 = False #multiclass\n",
    "cond3 = False #propogate output\n",
    "#true f t is the !\n",
    "#F F F is the !!!\n",
    "fract = 0.2\n",
    "#inputs, outputs = load_anomaly([input_path, output_path], cond1, cond2, cond3)\n",
    "steping = 150\n",
    "inputs, outputs = load_anomaly(input_path, output_path, cond1, cond2, cond3, fract, steping)\n",
    "\n",
    "inputs.shape\n",
    "\n",
    "outputs.shape\n",
    "\n",
    "outputs = one_hot_encode(outputs)\n",
    "outputs\n",
    "\n",
    "data = xr.concat([inputs, outputs], dim=\"features\")\n",
    "data.shape\n",
    "\n",
    "split_sequence = SplitSequence(\n",
    "    10, \n",
    "    1, \n",
    "    0, \n",
    "    sequence_inputs=data.coords[\"features\"].values[:-2], \n",
    "    sequence_outputs=data.coords[\"features\"].values[-2:],\n",
    ")\n",
    "inputs, outputs = split_sequence.split(data)\n",
    "\n",
    "\n",
    "inputs.shape\n",
    "\n",
    "outputs.shape\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(inputs, outputs, test_size=0.3)\n",
    "xtrain, xtest, x_scaler = scale_data(xtrain, xtest, scaler=MinMaxScaler())\n",
    "ytrain, ytest, y_scaler = scale_data(ytrain, ytest, scaler=MinMaxScaler())\n",
    "\n",
    "\n",
    "xtrain.shape\n",
    "\n",
    "ytrain.shape\n",
    "\n",
    "#ytrain\n",
    "\n",
    "#frequency = np.sum(ytrain, axis=0)\n",
    "\n",
    "# Categories\n",
    "#categories = ['Fault', 'NonFault']\n",
    "\n",
    "# Plot\n",
    "#plt.bar(categories, frequency)\n",
    "#plt.title('Frequency of One-Hot Fault/Non Fault')\n",
    "#plt.xlabel('Categories')\n",
    "#plt.ylabel('Frequency')\n",
    "#plt.ticklabel_format(style='plain', axis='y')\n",
    "#plt.show()\n",
    "#ytrain\n",
    "\n",
    "lstm_structure = {\n",
    "    \"LSTM_input\": {\n",
    "        \"units\": 50,\n",
    "        \"input_shape\": xtrain.shape[1:],\n",
    "        \"activation\": \"tanh\",\n",
    "        \"recurrent_activation\": \"sigmoid\",\n",
    "        \"return_sequences\": True,\n",
    "    },\n",
    "    \"LSTM\": {\n",
    "        \"num_layers\": mai.Int(0, 3),\n",
    "        \"units\": 50,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"recurrent_activation\": \"sigmoid\",\n",
    "        \"return_sequences\": True,\n",
    "    },\n",
    "\n",
    "\n",
    "        \n",
    "    \"GRU\": {  # Adding GRU layer\n",
    "        \"num_layers\": mai.Int(min_value=0, max_value=3),\n",
    "        \"units\": 50,\n",
    "        \"return_sequences\": True,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"recurrent_activation\": \"sigmoid\",\n",
    "\n",
    "    },\n",
    "    \"LSTM_output\": {\n",
    "        \"units\": 50,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"recurrent_activation\": \"sigmoid\",\n",
    "    },\n",
    "    \"Dense\": {\n",
    "        \"num_layers\": mai.Int(0, 3),\n",
    "        \"units\": 25,\n",
    "        \"activation\": \"relu\",\n",
    "    },\n",
    "    \"Dense_output\": {\n",
    "        \"units\": ytrain.shape[-1],\n",
    "        \"activation\": \"sigmoid\",\n",
    "    },\n",
    "}\n",
    "\n",
    "model_settings = {\n",
    "    \"models\": [\"LSTM\"],#, \"GRU\"],\n",
    "    \"LSTM\": {\n",
    "        \"structural_params\": lstm_structure,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"Adam\": {\"learning_rate\": mai.Float(1e-5, 0.001)},\n",
    "        \"compile_params\": {\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metrics\": [\"accuracy\"],\n",
    "        },\n",
    "        \"fitting_params\": {\n",
    "            \"batch_size\": mai.Choice([16, 32, 64, 128, 256, 512]),\n",
    "            \"epochs\": 5,\n",
    "            \"validation_split\": 0.15,\n",
    "        },\n",
    "    },\n",
    " #   \"GRU\": {\n",
    "  #      \"structural_params\": lstm_structure,\n",
    "  #      \"optimizer\": \"Adam\",\n",
    "   #     \"Adam\": {\"learning_rate\": mai.Float(1e-5, 0.001)},\n",
    "    #    \"compile_params\": {\n",
    "     #       \"loss\": \"binary_crossentropy\",\n",
    "      #      \"metrics\": [\"accuracy\"],\n",
    "  #      },\n",
    "   #     \"fitting_params\": {\n",
    "    #        \"batch_size\": mai.Choice([16, 32, 64, 128, 256, 512]),\n",
    "     #       \"epochs\": 5,\n",
    "      #      \"validation_split\": 0.15,\n",
    "       # },\n",
    "  #  },\n",
    "  #  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tuner = mai.Tuner(xtrain, ytrain, model_settings=model_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "feca9992-46b7-49f8-8a2d-e7a856479619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9cc2d00-1f25-4e6e-8fa6-92a2b7913527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 21, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d655ce0b-23df-491e-a792-52b0c594fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameter tuning neural networks with bayesian search\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2                 |2                 |LSTM_num_layers\n",
      "2                 |2                 |GRU_num_layers\n",
      "0                 |0                 |Dense_num_layers\n",
      "0.00069335        |0.00069335        |Adam_learning_rate\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jacc/pyMAISE/pyMAISE/utils/cvtuner.py\", line 91, in run_trial\n",
      "    self.hypermodel.fit(\n",
      "  File \"/home/jacc/pyMAISE/pyMAISE/methods/nn/_nn_hypermodel.py\", line 142, in fit\n",
      "    return model.fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_fileav9rahki.py\", line 18, in tf__train_function\n",
      "    raise\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n",
      "        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n",
      "    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/backend.py\", line 5822, in binary_crossentropy\n",
      "        return tf.nn.sigmoid_cross_entropy_with_logits(\n",
      "\n",
      "    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 21, 2)).\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 1.\nTraceback (most recent call last):\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacc/pyMAISE/pyMAISE/utils/cvtuner.py\", line 91, in run_trial\n    self.hypermodel.fit(\n  File \"/home/jacc/pyMAISE/pyMAISE/methods/nn/_nn_hypermodel.py\", line 142, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_fileav9rahki.py\", line 18, in tf__train_function\n    raise\nValueError: in user code:\n\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/backend.py\", line 5822, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 21, 2)).\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesSplit\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m bayesian_search_configs \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mnn_bayesian_search(\n\u001b[1;32m      6\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      8\u001b[0m     cv\u001b[38;5;241m=\u001b[39mTimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperparameter tuning took \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minutes to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/pyMAISE/pyMAISE/tuner.py:894\u001b[0m, in \u001b[0;36mTuner.nn_bayesian_search\u001b[0;34m(self, models, objective, max_trials, num_initial_points, alpha, beta, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, overwrite, directory, project_name, cv, shuffle)\u001b[0m\n\u001b[1;32m    880\u001b[0m kt_objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_kt_objective(objective)\n\u001b[1;32m    881\u001b[0m oracle \u001b[38;5;241m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    882\u001b[0m     objective\u001b[38;5;241m=\u001b[39mkt_objective[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    883\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m     max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    893\u001b[0m )\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nn_tuning(\n\u001b[1;32m    895\u001b[0m     models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[1;32m    896\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    897\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    898\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m    899\u001b[0m     oracle\u001b[38;5;241m=\u001b[39moracle,\n\u001b[1;32m    900\u001b[0m     metrics\u001b[38;5;241m=\u001b[39mkt_objective[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    901\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m    902\u001b[0m     directory\u001b[38;5;241m=\u001b[39mdirectory,\n\u001b[1;32m    903\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mproject_name,\n\u001b[1;32m    904\u001b[0m )\n",
      "File \u001b[0;32m~/pyMAISE/pyMAISE/tuner.py:1038\u001b[0m, in \u001b[0;36mTuner._nn_tuning\u001b[0;34m(self, models, objective, cv, shuffle, oracle, metrics, overwrite, directory, project_name)\u001b[0m\n\u001b[1;32m   1025\u001b[0m tuner \u001b[38;5;241m=\u001b[39m CVTuner(\n\u001b[1;32m   1026\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m   1027\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mproject_name,\n\u001b[1;32m   1035\u001b[0m )\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# Run search\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xtrain, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ytrain)\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# Get best hyperparameters\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(settings\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mnum_configs_saved)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mend_trial(trial)\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_consecutive_failures()\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 1.\nTraceback (most recent call last):\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/jacc/pyMAISE/pyMAISE/utils/cvtuner.py\", line 91, in run_trial\n    self.hypermodel.fit(\n  File \"/home/jacc/pyMAISE/pyMAISE/methods/nn/_nn_hypermodel.py\", line 142, in fit\n    return model.fit(\n           ^^^^^^^^^^\n  File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_fileav9rahki.py\", line 18, in tf__train_function\n    raise\nValueError: in user code:\n\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/jacc/anaconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/backend.py\", line 5822, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 21, 2)).\n\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "start = time.time()\n",
    "\n",
    "bayesian_search_configs = tuner.nn_bayesian_search(\n",
    "    objective=\"accuracy_score\",\n",
    "    max_trials=20,\n",
    "    cv=TimeSeriesSplit(n_splits=2),\n",
    ")\n",
    "\n",
    "print(\"Hyperparameter tuning took \" + str((time.time() - start) / 60) + \" minutes to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9c88a-91ff-4040-909a-d1e81cdaeb21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa33b9b-28ba-45a6-839e-dd65df004812",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b27d4-a9f6-4c09-b18c-dff5252843f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f3f9b-e398-47ea-bc17-abacdc982ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = mai.PostProcessor(\n",
    "    data=(xtrain, xtest, ytrain, ytest), \n",
    "    model_configs=[bayesian_search_configs], \n",
    "    new_model_settings={\n",
    "        \"FNN\": {\"fitting_params\": {\"epochs\": 500}},\n",
    "    },\n",
    "  #  y_scaler=y_scaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3316356",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd3bf8-839a-4815-b9ae-bea5aed288c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [ \"LSTM\"]:\n",
    "    for key, value in postprocessor.get_params(model_type=model).to_dict().items():\n",
    "        print(f\"{key}: {value[0]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6146e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = postprocessor._get_idx()\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9383e-a60c-49be-8e77-5440303bb0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#postprocessor._models()\n",
    "yhat_test = postprocessor._models[\"Test Yhat\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24637d-ed75-4baa-be27-3b8bb377c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818591a-bee9-4057-aea4-7eefd6b1dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    " yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731fd64-ffcf-4647-aeaf-cef38b054396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#postprocessor.confusion_matrix(model_type = \"LSTM\")\n",
    "yhat_train = postprocessor._models[\"Train Yhat\"][idx]\n",
    "yhat_test = postprocessor._models[\"Test Yhat\"][idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cb50c-650d-4b51-83af-40c9cd74ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = postprocessor._ytrain.values\n",
    "ytest = postprocessor._ytest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd140d-5bc4-4c1e-a3d4-38fa18f1e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ef1c8-be74-4289-9fce-6fd74907912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ytrain = y_scaler.inverse_transform(\n",
    "                ytrain.reshape(-1, ytrain.shape[-1])\n",
    "            )\n",
    "ytest = y_scaler.inverse_transform(ytest.reshape(-1, ytest.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b110e4-a70e-4335-936a-f7688a4c465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bdd0cf-bd6e-420b-9942-09834d6e1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.round(ytrain).astype(int)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07c52e-c75d-4b47-8980-8a6e9243d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f51a69-c0fb-4684-8649-ef12a16be064",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_single = np.argmax(yhat_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb008a-a929-44dd-b322-206c76f7d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_single = np.argmax(ytrain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20716de7-6c11-4b96-a297-1fd2d1698f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fca9a8-8867-4427-9e5a-b11eff240952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ace55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    r2_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_cm = confusion_matrix(ytrain_single , yhat_train_single)\n",
    "train_disp = ConfusionMatrixDisplay(confusion_matrix=train_cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aa42b-de97-431c-95c8-3c8fcd042e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33512ab7-0146-41d7-89ba-8036a3c0d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = np.round(ytest).astype(int)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e022ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23523676",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_single = np.argmax(yhat_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_single = np.argmax(ytest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295035ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb92f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_cm = confusion_matrix(ytest_single, yhat_test_single)\n",
    "test_disp = ConfusionMatrixDisplay(confusion_matrix=test_cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745db918",
   "metadata": {},
   "outputs": [],
   "source": [
    "##use pyMAISE one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c01b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c0f0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5de5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21cb1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bb600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25434a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f738d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a27c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cb207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabfde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33570f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab93e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9737280c-ab03-45e0-810b-d95a78d00451",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
