{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662efe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b052a3",
   "metadata": {},
   "source": [
    "## pyMAISE Initialization\n",
    "\n",
    "First we initialize pyMAISE with the following 4 parameters:\n",
    "\n",
    "- `verbosity`: 0 $\\rightarrow$ pyMAISE prints no outputs,\n",
    "- `random_state`: None $\\rightarrow$ No random seed is set,\n",
    "- `test_size`: 0.3 $\\rightarrow$ 30% of the data is used for testing,\n",
    "- `num_configs_saved`: 5 $\\rightarrow$ The top 5 hyper-parameter configurations are saved for each model.\n",
    "\n",
    "With pyMAISE initialized we can load the preprocessor for this data set using `load_fp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3928735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:57:32.278251: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 21:57:35.692809: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 21:57:35.773355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-10 21:57:48.740098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-10 21:57:51.442519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-10 21:57:51.444322: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import pyMAISE as mai\n",
    "import pytest\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Regression test parameters\n",
    "# Data set parameters\n",
    "num_observations = 150\n",
    "num_features = 4\n",
    "num_outputs = 1\n",
    "\n",
    "expected_models = {\n",
    "    \"dtree\": 1.0,\n",
    "    \"rforest\": 1.0,\n",
    "    \"knn\": 1.0,\n",
    "    \n",
    "}\n",
    "\n",
    "# Expected Model Settings\n",
    "matplotlib_settings = {\n",
    "    \"font.size\": 14,\n",
    "    \"legend.fontsize\": 12,\n",
    "}\n",
    "plus_minus= 0.025\n",
    "\n",
    "settings = { \n",
    "    \"verbosity\": 0,\n",
    "    \"random_state\": 42,\n",
    "    \"test_size\": 0.3,\n",
    "    \"num_configs_saved\": 1,\n",
    "    \"regression\": False,\n",
    "    \"classification\": True,\n",
    "}\n",
    "\n",
    "\n",
    "global_settings = mai.settings.init(settings_changes=settings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = mai.load_iris()\n",
    "data = preprocessor.data_split()\n",
    "\n",
    "model_settings = { \"models\": [\"logistic\", \"dtree\", \"rforest\", \"knn\"],\n",
    "                 }\n",
    "\n",
    "\n",
    "tuning = mai.Tuning(data=data, model_settings=model_settings)\n",
    "\n",
    "grid_search_spaces = {\n",
    "    \"logistic\":{\n",
    "        \"penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "        \"dual\": [True, False],\n",
    "        \"tol\": [0.001],\n",
    "    },\n",
    "    \"dtree\":{\n",
    "        \"max_depth\": [None, 5, 10, 25, 50],\n",
    "        \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 8, 10],\n",
    "        \"min_samples_split\": [2, 4, 6, 8, 10],\n",
    "    },\n",
    "    \"rforest\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "                      \n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"n_neighbors\": [1, 2, 4, 6, 8, 10, 14, 17, 20],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"leaf_size\": [1, 5, 10, 15, 20, 30],\n",
    "    },\n",
    "}\n",
    "grid_search_configs = tuning.grid_search(param_spaces=grid_search_spaces, models=grid_search_spaces.keys(), cv=ShuffleSplit(n_splits=1, test_size=0.15, random_state=global_settings.random_state),)\n",
    "\n",
    "postprocessor = mai.PostProcessor(\n",
    "    data=data,\n",
    "    models_list=[grid_search_configs],\n",
    ")\n",
    "\n",
    "for key, value in expected_models.items():\n",
    "    assert postprocessor.metrics(model_type=key)[\"Test Accuracy\"].to_numpy()[0] == pytest.approx(value, plus_minus / value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83806815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Types</th>\n",
       "      <th>Parameter Configurations</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>{'dual': False, 'penalty': 'l2', 'tol': 0.001}</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtree</td>\n",
       "      <td>{'max_depth': None, 'max_features': None, 'min...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rforest</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'leaf_size': 10, 'n_neighbors': 20, 'weights'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Types                           Parameter Configurations  \\\n",
       "0    logistic     {'dual': False, 'penalty': 'l2', 'tol': 0.001}   \n",
       "1       dtree  {'max_depth': None, 'max_features': None, 'min...   \n",
       "2     rforest  {'criterion': 'gini', 'max_features': 'sqrt', ...   \n",
       "3         knn  {'leaf_size': 10, 'n_neighbors': 20, 'weights'...   \n",
       "\n",
       "   Train Accuracy  Train Recall  Train Precision  Train F1  Test Accuracy  \\\n",
       "0        0.961905      0.961905         0.961905  0.961905            1.0   \n",
       "1        1.000000      1.000000         1.000000  1.000000            1.0   \n",
       "2        1.000000      1.000000         1.000000  1.000000            1.0   \n",
       "3        1.000000      1.000000         1.000000  1.000000            1.0   \n",
       "\n",
       "   Test Recall  Test Precision  Test F1  \n",
       "0          1.0             1.0      1.0  \n",
       "1          1.0             1.0      1.0  \n",
       "2          1.0             1.0      1.0  \n",
       "3          1.0             1.0      1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postprocessor.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b24c5",
   "metadata": {},
   "source": [
    "# New NN Object using MIT Reactor Data for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fbdd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- NEW TEST ---------------\n",
      "{'structural_hyperparameters.dense_input.num_nodes': 12, 'structural_hyperparameters.dense_input.input_dim': 6, 'structural_hyperparameters.dense_input.activation': 'relu', 'structural_hyperparameters.dense.num_nodes': 15, 'structural_hyperparameters.dense.shape': None, 'structural_hyperparameters.dense.activation': 'relu', 'structural_hyperparameters.dense_output.num_nodes': 118, 'structural_hyperparameters.dense_output.shape': 22, 'structural_hyperparameters.dense_output.activation': 'relu'}\n",
      "--------- NEW TEST ---------------\n",
      "[INFO] performing hyperparameter search...\n",
      "[INFO] optimal number of units in dense layer: 85\n",
      "[INFO] training the best model...\n",
      "Epoch 1/50\n",
      "22/22 [==============================] - 16s 533ms/step - loss: 19886.1621 - mean_absolute_error: 19886.1621 - val_loss: 19885.4629 - val_mean_absolute_error: 19885.4629\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 8s 377ms/step - loss: 19885.3066 - mean_absolute_error: 19885.3066 - val_loss: 19884.5684 - val_mean_absolute_error: 19884.5684\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 20s 947ms/step - loss: 19884.3535 - mean_absolute_error: 19884.3535 - val_loss: 19883.5449 - val_mean_absolute_error: 19883.5449\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19883.2363 - mean_absolute_error: 19883.2363 - val_loss: 19882.3027 - val_mean_absolute_error: 19882.3027\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 19881.8477 - mean_absolute_error: 19881.8477 - val_loss: 19880.7324 - val_mean_absolute_error: 19880.7324\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 21s 956ms/step - loss: 19880.0879 - mean_absolute_error: 19880.0879 - val_loss: 19878.7988 - val_mean_absolute_error: 19878.7988\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 25s 1s/step - loss: 19877.9043 - mean_absolute_error: 19877.9043 - val_loss: 19876.3125 - val_mean_absolute_error: 19876.3125\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19875.1855 - mean_absolute_error: 19875.1855 - val_loss: 19873.3887 - val_mean_absolute_error: 19873.3887\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 9s 441ms/step - loss: 19872.0605 - mean_absolute_error: 19872.0605 - val_loss: 19870.0371 - val_mean_absolute_error: 19870.0371\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 19868.4609 - mean_absolute_error: 19868.4609 - val_loss: 19866.1699 - val_mean_absolute_error: 19866.1699\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 27s 1s/step - loss: 19864.2852 - mean_absolute_error: 19864.2852 - val_loss: 19861.6621 - val_mean_absolute_error: 19861.6621\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 10s 463ms/step - loss: 19859.4082 - mean_absolute_error: 19859.4082 - val_loss: 19856.3926 - val_mean_absolute_error: 19856.3926\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 30s 1s/step - loss: 19853.7109 - mean_absolute_error: 19853.7109 - val_loss: 19850.2363 - val_mean_absolute_error: 19850.2363\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 8s 384ms/step - loss: 19847.0547 - mean_absolute_error: 19847.0547 - val_loss: 19843.0352 - val_mean_absolute_error: 19843.0352\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 25s 1s/step - loss: 19839.2520 - mean_absolute_error: 19839.2520 - val_loss: 19834.6094 - val_mean_absolute_error: 19834.6094\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 19830.2246 - mean_absolute_error: 19830.2246 - val_loss: 19824.9707 - val_mean_absolute_error: 19824.9707\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19819.9551 - mean_absolute_error: 19819.9551 - val_loss: 19814.0625 - val_mean_absolute_error: 19814.0625\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 9s 447ms/step - loss: 19808.3496 - mean_absolute_error: 19808.3496 - val_loss: 19801.7520 - val_mean_absolute_error: 19801.7520\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 30s 1s/step - loss: 19795.2949 - mean_absolute_error: 19795.2949 - val_loss: 19787.9453 - val_mean_absolute_error: 19787.9453\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 10s 483ms/step - loss: 19780.7109 - mean_absolute_error: 19780.7109 - val_loss: 19772.5957 - val_mean_absolute_error: 19772.5957\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 24s 1s/step - loss: 19764.5469 - mean_absolute_error: 19764.5469 - val_loss: 19755.6250 - val_mean_absolute_error: 19755.6250\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 19s 882ms/step - loss: 19746.7207 - mean_absolute_error: 19746.7207 - val_loss: 19736.9766 - val_mean_absolute_error: 19736.9766\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 18s 839ms/step - loss: 19727.1875 - mean_absolute_error: 19727.1875 - val_loss: 19716.5605 - val_mean_absolute_error: 19716.5605\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 25s 1s/step - loss: 19705.8477 - mean_absolute_error: 19705.8477 - val_loss: 19694.3457 - val_mean_absolute_error: 19694.3457\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 7s 322ms/step - loss: 19682.6621 - mean_absolute_error: 19682.6621 - val_loss: 19670.2520 - val_mean_absolute_error: 19670.2520\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 24s 1s/step - loss: 19657.5605 - mean_absolute_error: 19657.5605 - val_loss: 19644.2207 - val_mean_absolute_error: 19644.2207\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19630.5098 - mean_absolute_error: 19630.5098 - val_loss: 19616.1504 - val_mean_absolute_error: 19616.1504\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 16s 768ms/step - loss: 19601.3887 - mean_absolute_error: 19601.3887 - val_loss: 19586.0586 - val_mean_absolute_error: 19586.0586\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 22s 1s/step - loss: 19570.1875 - mean_absolute_error: 19570.1875 - val_loss: 19553.8516 - val_mean_absolute_error: 19553.8516\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 20s 912ms/step - loss: 19536.8359 - mean_absolute_error: 19536.8359 - val_loss: 19519.3828 - val_mean_absolute_error: 19519.3828\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 22s 1s/step - loss: 19501.1387 - mean_absolute_error: 19501.1387 - val_loss: 19482.5859 - val_mean_absolute_error: 19482.5859\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 19463.0957 - mean_absolute_error: 19463.0957 - val_loss: 19443.4258 - val_mean_absolute_error: 19443.4258\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19422.6836 - mean_absolute_error: 19422.6836 - val_loss: 19401.8574 - val_mean_absolute_error: 19401.8574\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 18s 838ms/step - loss: 19379.8223 - mean_absolute_error: 19379.8223 - val_loss: 19357.8711 - val_mean_absolute_error: 19357.8711\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 18s 866ms/step - loss: 19334.5137 - mean_absolute_error: 19334.5137 - val_loss: 19311.3926 - val_mean_absolute_error: 19311.3926\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 19286.6992 - mean_absolute_error: 19286.6992 - val_loss: 19262.3457 - val_mean_absolute_error: 19262.3457\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 22s 1s/step - loss: 19236.1523 - mean_absolute_error: 19236.1523 - val_loss: 19210.4824 - val_mean_absolute_error: 19210.4824\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 20s 945ms/step - loss: 19182.7793 - mean_absolute_error: 19182.7793 - val_loss: 19155.7754 - val_mean_absolute_error: 19155.7754\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 24s 1s/step - loss: 19126.5703 - mean_absolute_error: 19126.5703 - val_loss: 19098.2715 - val_mean_absolute_error: 19098.2715\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 10s 483ms/step - loss: 19067.5664 - mean_absolute_error: 19067.5664 - val_loss: 19037.8711 - val_mean_absolute_error: 19037.8711\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 25s 1s/step - loss: 19005.6035 - mean_absolute_error: 19005.6035 - val_loss: 18974.6484 - val_mean_absolute_error: 18974.6484\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 21s 993ms/step - loss: 18940.7090 - mean_absolute_error: 18940.7090 - val_loss: 18908.3750 - val_mean_absolute_error: 18908.3750\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 25s 1s/step - loss: 18872.7793 - mean_absolute_error: 18872.7793 - val_loss: 18839.0234 - val_mean_absolute_error: 18839.0234\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 31s 1s/step - loss: 18801.7598 - mean_absolute_error: 18801.7598 - val_loss: 18766.6270 - val_mean_absolute_error: 18766.6270\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 24s 1s/step - loss: 18727.6562 - mean_absolute_error: 18727.6562 - val_loss: 18691.1582 - val_mean_absolute_error: 18691.1582\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 28s 1s/step - loss: 18650.4707 - mean_absolute_error: 18650.4707 - val_loss: 18612.5391 - val_mean_absolute_error: 18612.5391\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 26s 1s/step - loss: 18570.1074 - mean_absolute_error: 18570.1074 - val_loss: 18530.7930 - val_mean_absolute_error: 18530.7930\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 29s 1s/step - loss: 18486.5957 - mean_absolute_error: 18486.5938 - val_loss: 18445.8438 - val_mean_absolute_error: 18445.8438\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 23s 1s/step - loss: 18399.8633 - mean_absolute_error: 18399.8633 - val_loss: 18357.6797 - val_mean_absolute_error: 18357.6797\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 24s 1s/step - loss: 18309.8711 - mean_absolute_error: 18309.8711 - val_loss: 18266.3027 - val_mean_absolute_error: 18266.3027\n",
      "[INFO] evaluating network...\n",
      "10/10 [==============================] - 6s 55ms/step\n",
      "-11195.249330360535\n"
     ]
    }
   ],
   "source": [
    "import pyMAISE as mai\n",
    "from pyMAISE.methods import *\n",
    "import pytest\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "import flatdict\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "global_settings = mai.settings.init({\"regression\": True})\n",
    "\n",
    "preprocessor = mai.load_MITR()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = preprocessor.data_split()\n",
    "\n",
    "\n",
    "print(\"--------- NEW TEST ---------------\")\n",
    "optimizer_hyperparameters = {\n",
    "    # Optimizer\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.0099,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 27,\n",
    "    \"loss\": \"mean_absolute_error\",\n",
    "    \"metrics\": [\"mean_absolute_error\"],\n",
    "    \"warm_start\": True,\n",
    "    \"jit_compile\": False,\n",
    "    \n",
    "}\n",
    "\n",
    "structural_hyperparameters = {\n",
    "    \"structural_hyperparameters\":{\n",
    "        \"dense_input\": {\n",
    "            \"num_nodes\": 12, \n",
    "            \"input_dim\": preprocessor.inputs.shape[1],\n",
    "            \"activation\": 'relu',\n",
    "            },\n",
    "        \"dense\": {\n",
    "            \"num_nodes\": 15,\n",
    "            \"shape\": None,\n",
    "            \"activation\": 'relu',\n",
    "        },\n",
    "        \"dense_output\": {\n",
    "            \"num_nodes\": 118,\n",
    "            \"shape\": preprocessor.outputs.shape[1],\n",
    "            \"activation\": 'relu',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "}\n",
    "# An example that we ould do to flatten the dictionary for the potential issue you said about milti dim dictionary\n",
    "d =  flatdict.FlatDict(structural_hyperparameters, delimiter='.')\n",
    "print(d)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Using the Baysian Search I saw\n",
    "\n",
    "print(\"--------- NEW TEST ---------------\")\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "\n",
    "\n",
    "optimizer_hyperparameters = {\n",
    "    # Optimizer\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-4, # hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, default=1e-3):w\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 27,\n",
    "    \"loss\": \"mean_absolute_error\",\n",
    "    \"metrics\": [\"mean_absolute_error\"],\n",
    "    \"warm_start\": True,\n",
    "    \"jit_compile\": False,\n",
    "    \n",
    "}\n",
    "\n",
    "structural_hyperparameters = {\n",
    "    \"structural_hyperparameters\":{\n",
    "        \"dense_input\": {\n",
    "            \"num_nodes\": 100, # hp.Int('units1', min_value=50, max_value=350, step=50), \n",
    "            \"input_dim\": preprocessor.inputs.shape[1],\n",
    "            \"activation\": 'relu',\n",
    "            },\n",
    "        \"dense\": {\n",
    "            \"num_nodes\": [50, 100, 5], # hp.Int('units2', min_value=50, max_value=100, step=25),\n",
    "            \"input_dim\": None,\n",
    "            \"activation\": 'relu',\n",
    "        },\n",
    "        \"dense_output\": {\n",
    "            \"num_nodes\":  preprocessor.outputs.shape[1], # hp.Int('units3', min_value=50, max_value=100, step=25),\n",
    "            \"input_dim\": None,\n",
    "            \"activation\": 'relu',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "build_model = nnHyperModel(structural_hyperparameters, optimizer_hyperparameters)\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "        build_model,\n",
    "        objective=\"mean_absolute_error\",\n",
    "        max_trials=10,\n",
    "        seed=42)\n",
    "print(\"[INFO] performing hyperparameter search...\")\n",
    "tuner.search(\n",
    "    x=xtrain,\n",
    "    y=ytrain,\n",
    "    validation_data=(xtest, ytest),\n",
    "    batch_size=50,\n",
    "    epochs=10,\n",
    ")\n",
    "# grab the best hyperparameters\n",
    "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"[INFO] optimal number of units in dense layer: {}\".format(\n",
    "\tbestHP.get(\"Units\")))\n",
    "\n",
    "# build the best model and train it\n",
    "print(\"[INFO] training the best model...\")\n",
    "model = tuner.hypermodel.build(bestHP)\n",
    "H = model.fit(x=xtrain, y=ytrain,\n",
    "validation_data=(xtest, ytest), batch_size=32,\n",
    "epochs=50, verbose=1)\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=xtest, batch_size=32)\n",
    "print(r2_score(ytest, predictions))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b4a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc78634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
